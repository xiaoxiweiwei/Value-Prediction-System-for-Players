{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68176804",
   "metadata": {},
   "source": [
    "## Task-I: Build and populate necessary tables (30% of course project grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249e631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you are using Windows\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4f67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SystemsToolChains\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this instead the upper section if running on the cloud\n",
    "\"\"\"\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "\n",
    "appName = \"fifa\"\n",
    "master = \"yarn\"\n",
    "\n",
    "conf = SparkConf().set('spark.driver.host', '127.0.0.1')\\\n",
    "                  .set(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.18\")\\\n",
    "                  .setAppName(appName)\\\n",
    "                  .setMaster(master)\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sc.getConf()).getOrCreate()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d8224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you are running on GCP\n",
    "# change hdfs://cluster-2ca4-m/ based on your cluster node\n",
    "# !hdfs dfs -put \"/archive\" hdfs://cluster-2ca4-m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fa4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for year in range(15, 23):\n",
    "    file_path = f\"archive/players_{year}.csv\"\n",
    "    file_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c66636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " sofifa_id                   | 158023               \n",
      " player_url                  | https://sofifa.co... \n",
      " short_name                  | L. Messi             \n",
      " long_name                   | Lionel Andr√©s Mes... \n",
      " player_positions            | CF                   \n",
      " overall                     | 93                   \n",
      " potential                   | 95                   \n",
      " value_eur                   | 1.005E8              \n",
      " wage_eur                    | 550000.0             \n",
      " age                         | 27                   \n",
      " dob                         | 1987-06-24           \n",
      " height_cm                   | 169                  \n",
      " weight_kg                   | 67                   \n",
      " club_team_id                | 241.0                \n",
      " club_name                   | FC Barcelona         \n",
      " league_name                 | Spain Primera Div... \n",
      " league_level                | 1                    \n",
      " club_position               | CF                   \n",
      " club_jersey_number          | 10                   \n",
      " club_loaned_from            | null                 \n",
      " club_joined                 | 2004-07-01           \n",
      " club_contract_valid_until   | 2018                 \n",
      " nationality_id              | 52                   \n",
      " nationality_name            | Argentina            \n",
      " nation_team_id              | 1369.0               \n",
      " nation_position             | CF                   \n",
      " nation_jersey_number        | 10                   \n",
      " preferred_foot              | Left                 \n",
      " weak_foot                   | 3                    \n",
      " skill_moves                 | 4                    \n",
      " international_reputation    | 5                    \n",
      " work_rate                   | Medium/Low           \n",
      " body_type                   | Normal (170-)        \n",
      " real_face                   | Yes                  \n",
      " release_clause_eur          | null                 \n",
      " player_tags                 | #Speedster, #Drib... \n",
      " player_traits               | Finesse Shot, Spe... \n",
      " pace                        | 93                   \n",
      " shooting                    | 89                   \n",
      " passing                     | 86                   \n",
      " dribbling                   | 96                   \n",
      " defending                   | 27                   \n",
      " physic                      | 63                   \n",
      " attacking_crossing          | 84                   \n",
      " attacking_finishing         | 94                   \n",
      " attacking_heading_accuracy  | 71                   \n",
      " attacking_short_passing     | 89                   \n",
      " attacking_volleys           | 85                   \n",
      " skill_dribbling             | 96                   \n",
      " skill_curve                 | 89                   \n",
      " skill_fk_accuracy           | 90                   \n",
      " skill_long_passing          | 76                   \n",
      " skill_ball_control          | 96                   \n",
      " movement_acceleration       | 96                   \n",
      " movement_sprint_speed       | 90                   \n",
      " movement_agility            | 94                   \n",
      " movement_reactions          | 94                   \n",
      " movement_balance            | 95                   \n",
      " power_shot_power            | 80                   \n",
      " power_jumping               | 73                   \n",
      " power_stamina               | 77                   \n",
      " power_strength              | 60                   \n",
      " power_long_shots            | 88                   \n",
      " mentality_aggression        | 48                   \n",
      " mentality_interceptions     | 22                   \n",
      " mentality_positioning       | 92                   \n",
      " mentality_vision            | 90                   \n",
      " mentality_penalties         | 76                   \n",
      " mentality_composure         | null                 \n",
      " defending_marking_awareness | 25                   \n",
      " defending_standing_tackle   | 21                   \n",
      " defending_sliding_tackle    | 20                   \n",
      " goalkeeping_diving          | 6                    \n",
      " goalkeeping_handling        | 11                   \n",
      " goalkeeping_kicking         | 15                   \n",
      " goalkeeping_positioning     | 14                   \n",
      " goalkeeping_reflexes        | 8                    \n",
      " goalkeeping_speed           | null                 \n",
      " ls                          | 89+3                 \n",
      " st                          | 89+3                 \n",
      " rs                          | 89+3                 \n",
      " lw                          | 92+3                 \n",
      " lf                          | 90+3                 \n",
      " cf                          | 90+3                 \n",
      " rf                          | 90+3                 \n",
      " rw                          | 92+3                 \n",
      " lam                         | 92+3                 \n",
      " cam                         | 92+3                 \n",
      " ram                         | 92+3                 \n",
      " lm                          | 90+3                 \n",
      " lcm                         | 79+3                 \n",
      " cm                          | 79+3                 \n",
      " rcm                         | 79+3                 \n",
      " rm                          | 90+3                 \n",
      " lwb                         | 62+3                 \n",
      " ldm                         | 62+3                 \n",
      " cdm                         | 62+3                 \n",
      " rdm                         | 62+3                 \n",
      " rwb                         | 62+3                 \n",
      " lb                          | 54+3                 \n",
      " lcb                         | 45+3                 \n",
      " cb                          | 45+3                 \n",
      " rcb                         | 45+3                 \n",
      " rb                          | 54+3                 \n",
      " gk                          | 15+3                 \n",
      " player_face_url             | https://cdn.sofif... \n",
      " club_logo_url               | https://cdn.sofif... \n",
      " club_flag_url               | https://cdn.sofif... \n",
      " nation_logo_url             | https://cdn.sofif... \n",
      " nation_flag_url             | https://cdn.sofif... \n",
      " year                        | 15                   \n",
      " unique_id                   | 0                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "data_frames = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    \n",
    "    # Add a new column for the year.\n",
    "    year = int(file_path.split(\"_\")[1].split(\".\")[0])\n",
    "    df = df.withColumn('year', lit(year))\n",
    "    \n",
    "    # for test\n",
    "    # df.show(1, vertical = True)\n",
    "    \n",
    "    data_frames.append(df)\n",
    "\n",
    "merged_df = reduce(lambda x, y: x.union(y), data_frames)\n",
    "\n",
    "# Add a column unique_id so that every record can be uniquely identified\n",
    "merged_df = merged_df.withColumn(\"unique_id\", monotonically_increasing_id())\n",
    "\n",
    "merged_df.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110395ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the data from all years (2015-2022) into one Postgres Database table\n",
    "# change postgres_url based on your GCP PostgresSQL, change the user and password based on your own settings\n",
    "postgres_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "table_name = \"fifa.fifa_table\" \n",
    "\n",
    "merged_df.write.jdbc(url=postgres_url, table=table_name, mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4c752",
   "metadata": {},
   "source": [
    "## Task-II: Conduct analytics on your dataset (20% of course project grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1eca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the data from all years (2015-2022) into one Postgres Database table\n",
    "# change postgres_url based on your GCP PostgresSQL, change the user and password based on your own settings\n",
    "from pyspark.sql.functions import col, when, count, avg, desc, dense_rank, rank, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Read data from PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "db_properties = {\"user\": \"postgres\", \"password\": \"123\", \"driver\": \"org.postgresql.Driver\"}\n",
    "df = spark.read.jdbc(url=jdbc_url, table=\"fifa.fifa_table\", properties=db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b336cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 clubs that have the highest number of players with contracts ending in 2023\n",
      "+--------------------+------------+\n",
      "|           club_name|player_count|\n",
      "+--------------------+------------+\n",
      "|En Avant de Guingamp|          19|\n",
      "| Club Atl√©tico Lan√∫s|          17|\n",
      "|       Lechia Gda≈Ñsk|          17|\n",
      "|            Barnsley|          16|\n",
      "|        Kasimpa≈üa SK|          16|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_x(x):\n",
    "\n",
    "    # players whose contracts end in 2023\n",
    "    filtered_df = df.filter(df.year == 22)\n",
    "    filtered_df = filtered_df.filter(df.club_contract_valid_until == 2023)\n",
    "\n",
    "    # Task 1: X clubs with the highest number of players with contracts ending in 2023\n",
    "    x_clubs = filtered_df.groupBy(\"club_name\").agg(count(\"club_name\").alias(\"player_count\")) \\\n",
    "        .orderBy(desc(\"player_count\")).limit(x)\n",
    "    print(str(x)+' clubs that have the highest number of players with contracts ending in 2023')\n",
    "    x_clubs.show()\n",
    "    \n",
    "find_x(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5e8600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 clubs with the highest average number of players older than 27 years:\n",
      "+--------------------+---------------------+----+\n",
      "|           club_name|average_older_players|rank|\n",
      "+--------------------+---------------------+----+\n",
      "|  Dorados de Sinaloa|                 19.0|   1|\n",
      "| Matsumoto Yamaga FC|                 19.0|   1|\n",
      "| Shanghai Shenhua FC|                 18.5|   3|\n",
      "|          Qingdao FC|                 18.0|   4|\n",
      "|Club Deportivo Jo...|                 17.5|   5|\n",
      "+--------------------+---------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_y(y):\n",
    "    # drop row with club_name is null\n",
    "    filtered_df = df.filter(col(\"club_name\").isNotNull())\n",
    "    \n",
    "    # players whose age > 27\n",
    "    older_players = filtered_df.filter(col(\"age\") > 27)\n",
    "\n",
    "    # players whose age > 27 for each club per year\n",
    "    club_per_year = older_players.groupBy(\"club_name\", \"year\").agg(count(\"sofifa_id\").alias(\"older_players_count\"))\n",
    "\n",
    "    # average count per club \n",
    "    # Notice: taking into account clubs not available in certain years\n",
    "    avg_club_counts = club_per_year.groupBy(\"club_name\").agg(avg(\"older_players_count\").alias(\"average_older_players\"))\n",
    "\n",
    "    # rank clubs based on average count\n",
    "    window_spec = Window.orderBy(desc(\"average_older_players\"))\n",
    "    ranked_clubs = avg_club_counts.withColumn(\"rank\", rank().over(window_spec))\n",
    "    top_y_clubs = ranked_clubs.filter(col(\"rank\") <= y)\n",
    "    print('Top {} clubs with the highest average number of players older than 27 years:'.format(y))\n",
    "    top_y_clubs.show()\n",
    "\n",
    "find_y(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45fe402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent nation_position in the dataset for each year -- with substitute\n",
      "+----+---------------+-----+\n",
      "|year|nation_position|count|\n",
      "+----+---------------+-----+\n",
      "|  15|            SUB|  564|\n",
      "|  16|            SUB|  511|\n",
      "|  17|            SUB|  564|\n",
      "|  18|            SUB|  600|\n",
      "|  19|            SUB|  576|\n",
      "|  20|            SUB|  588|\n",
      "|  21|            SUB|  588|\n",
      "|  22|            SUB|  396|\n",
      "+----+---------------+-----+\n",
      "\n",
      "The most frequent nation_position in the dataset for each year -- without substitute\n",
      "+----+---------------+-----+\n",
      "|year|nation_position|count|\n",
      "+----+---------------+-----+\n",
      "|  15|            LCB|   47|\n",
      "|  15|            RCB|   47|\n",
      "|  15|             GK|   47|\n",
      "|  16|            RCB|   46|\n",
      "|  16|             GK|   46|\n",
      "|  17|             GK|   47|\n",
      "|  17|            LCB|   47|\n",
      "|  17|            RCB|   47|\n",
      "|  18|            LCB|   50|\n",
      "|  18|             GK|   50|\n",
      "|  18|            RCB|   50|\n",
      "|  19|            RCB|   48|\n",
      "|  19|             GK|   48|\n",
      "|  19|            LCB|   48|\n",
      "|  20|             GK|   49|\n",
      "|  20|            LCB|   49|\n",
      "|  20|            RCB|   49|\n",
      "|  21|            LCB|   49|\n",
      "|  21|            RCB|   49|\n",
      "|  21|             GK|   49|\n",
      "|  22|            RCB|   33|\n",
      "|  22|             GK|   33|\n",
      "|  22|            LCB|   33|\n",
      "+----+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_frequent_nation_position(substitute):\n",
    "    # drop row with nation_position is SUB (substitute)\n",
    "    if substitute:\n",
    "        filtered_df = df\n",
    "    else:\n",
    "        filtered_df = df.filter(col(\"nation_position\") != \"SUB\")\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "\n",
    "    # count nation_position per year\n",
    "    position_freq = filtered_df.groupBy(\"year\", \"nation_position\").agg(count(\"nation_position\").alias(\"count\"))\n",
    "    \n",
    "    # rank frequency per year\n",
    "    position_freq_ranked = position_freq.withColumn(\"rank\", rank().over(window_spec))\n",
    "    most_frequent_positions = position_freq_ranked.filter(col(\"rank\") == 1).select(\"year\", \"nation_position\", \"count\").orderBy(\"year\")\n",
    "    \n",
    "    print('The most frequent nation_position in the dataset for each year', end = \" -- \")\n",
    "    if(substitute):\n",
    "        print(\"with substitute\")\n",
    "    else:\n",
    "        print(\"without substitute\")\n",
    "    most_frequent_positions.show(most_frequent_positions.count()) # To display the complete data\n",
    "\n",
    "find_frequent_nation_position(True)\n",
    "find_frequent_nation_position(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa2e32",
   "metadata": {},
   "source": [
    "## Task III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e9af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_feature1 = ['st', 'rs','lw','lf','cf', 'rf','rw',\n",
    "              'lam','cam','ram','lm','lcm','cm','rcm',\n",
    "              'rm','lwb','ldm','cdm','rdm','rwb','lb',\n",
    "              'lcb','cb','rcb','rb','gk']\n",
    "skill_feature2 = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', 'attacking_crossing',\n",
    "                 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys',\n",
    "                 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',\n",
    "                 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions',\n",
    "                 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning',\n",
    "                 'mentality_vision', 'mentality_penalties', 'defending_marking_awareness', 'defending_standing_tackle',\n",
    "                 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
    "                 'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']\n",
    "feature_list = skill_feature1 + skill_feature2\n",
    "overall_list = feature_list + ['overall']\n",
    "player_df = merged_df[overall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cadbf402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " st_missing                          | 0      \n",
      " rs_missing                          | 0      \n",
      " lw_missing                          | 0      \n",
      " lf_missing                          | 0      \n",
      " cf_missing                          | 0      \n",
      " rf_missing                          | 0      \n",
      " rw_missing                          | 0      \n",
      " lam_missing                         | 0      \n",
      " cam_missing                         | 0      \n",
      " ram_missing                         | 0      \n",
      " lm_missing                          | 0      \n",
      " lcm_missing                         | 0      \n",
      " cm_missing                          | 0      \n",
      " rcm_missing                         | 0      \n",
      " rm_missing                          | 0      \n",
      " lwb_missing                         | 0      \n",
      " ldm_missing                         | 0      \n",
      " cdm_missing                         | 0      \n",
      " rdm_missing                         | 0      \n",
      " rwb_missing                         | 0      \n",
      " lb_missing                          | 0      \n",
      " lcb_missing                         | 0      \n",
      " cb_missing                          | 0      \n",
      " rcb_missing                         | 0      \n",
      " rb_missing                          | 0      \n",
      " gk_missing                          | 0      \n",
      " pace_missing                        | 15791  \n",
      " shooting_missing                    | 15791  \n",
      " passing_missing                     | 15791  \n",
      " dribbling_missing                   | 15791  \n",
      " defending_missing                   | 15791  \n",
      " physic_missing                      | 15791  \n",
      " attacking_crossing_missing          | 0      \n",
      " attacking_finishing_missing         | 0      \n",
      " attacking_heading_accuracy_missing  | 0      \n",
      " attacking_short_passing_missing     | 0      \n",
      " attacking_volleys_missing           | 0      \n",
      " skill_dribbling_missing             | 0      \n",
      " skill_curve_missing                 | 0      \n",
      " skill_fk_accuracy_missing           | 0      \n",
      " skill_long_passing_missing          | 0      \n",
      " skill_ball_control_missing          | 0      \n",
      " movement_acceleration_missing       | 0      \n",
      " movement_sprint_speed_missing       | 0      \n",
      " movement_agility_missing            | 0      \n",
      " movement_reactions_missing          | 0      \n",
      " movement_balance_missing            | 0      \n",
      " power_shot_power_missing            | 0      \n",
      " power_jumping_missing               | 0      \n",
      " power_stamina_missing               | 0      \n",
      " power_strength_missing              | 0      \n",
      " power_long_shots_missing            | 0      \n",
      " mentality_aggression_missing        | 0      \n",
      " mentality_interceptions_missing     | 0      \n",
      " mentality_positioning_missing       | 0      \n",
      " mentality_vision_missing            | 0      \n",
      " mentality_penalties_missing         | 0      \n",
      " defending_marking_awareness_missing | 0      \n",
      " defending_standing_tackle_missing   | 0      \n",
      " defending_sliding_tackle_missing    | 0      \n",
      " goalkeeping_diving_missing          | 0      \n",
      " goalkeeping_handling_missing        | 0      \n",
      " goalkeeping_kicking_missing         | 0      \n",
      " goalkeeping_positioning_missing     | 0      \n",
      " goalkeeping_reflexes_missing        | 0      \n",
      " goalkeeping_speed_missing           | 126288 \n",
      " overall_missing                     | 0      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_count = player_df.select(*[(sum(col(c).isNull().cast(\"int\")).alias(c + \"_missing\")) for c in player_df.columns])\n",
    "\n",
    "missing_count.show(vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c96617b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['goalkeeping_speed']\n",
    "columns_to_fill = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic']\n",
    "\n",
    "feature_list.remove('goalkeeping_speed')\n",
    "overall_list.remove('goalkeeping_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b866ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "class FeatureTypeCaster(Transformer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \n",
    "        output_df = dataset\n",
    "        for i in skill_feature1:\n",
    "            output_df = output_df.withColumn(i, split(output_df[i], \"\\\\+\")[0])\n",
    "            output_df = output_df.withColumn(i, split(output_df[i], \"\\\\-\")[0])\n",
    "            output_df = output_df.withColumn(i, output_df[i].cast(\"int\"))\n",
    "            \n",
    "        return output_df\n",
    "\n",
    "class ColumnDropper(Transformer):\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df\n",
    "\n",
    "class ColumnFillna(Transformer):\n",
    "    def __init__(self, columns_to_fill = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_fill = columns_to_fill\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_fill:\n",
    "            mean_value = output_df.select(mean(col_name)).collect()[0][0]\n",
    "            output_df = output_df.fillna(mean_value, subset=[col_name])\n",
    "        \n",
    "\n",
    "        return output_df\n",
    "\n",
    "def get_preprocess_pipeline():\n",
    "    # Cast the feature\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "    \n",
    "    # Scale the features\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = columns_to_drop)\n",
    "    \n",
    "    stage_column_fillna = ColumnFillna(columns_to_fill = columns_to_fill)\n",
    "    \n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_list, outputCol=\"vectorized_features\")\n",
    "    \n",
    "    # Connect the pipeline\n",
    "    pipeline = Pipeline(stages=[stage_typecaster,stage_column_dropper,stage_column_fillna,\n",
    "        stage_vector_assembler, stage_scaler])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09011f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " features | [6.58435804760700... \n",
      " overall  | 93                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_pipeline = get_preprocess_pipeline()\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(player_df)\n",
    "players = preprocess_pipeline_model.transform(player_df)\n",
    "players = players['features', 'overall']\n",
    "players.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e251fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature column: feature_list\n",
    "# output column: overall\n",
    "\n",
    "seed = 2023\n",
    "train_df, val_df, test_df = players.randomSplit([0.6, 0.2, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5237a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'regParam': 0.01, 'maxIter': 10}ÔºåValidation RMSE: 2.7936499275036044\n",
      "Params: {'regParam': 0.01, 'maxIter': 30}ÔºåValidation RMSE: 2.793649927503598\n",
      "Params: {'regParam': 0.01, 'maxIter': 50}ÔºåValidation RMSE: 2.7936499275035835\n",
      "Params: {'regParam': 0.1, 'maxIter': 10}ÔºåValidation RMSE: 2.8054156039487985\n",
      "Params: {'regParam': 0.1, 'maxIter': 30}ÔºåValidation RMSE: 2.8054156039488265\n",
      "Params: {'regParam': 0.1, 'maxIter': 50}ÔºåValidation RMSE: 2.805415603948817\n",
      "Params: {'regParam': 1.0, 'maxIter': 10}ÔºåValidation RMSE: 2.913144924746847\n",
      "Params: {'regParam': 1.0, 'maxIter': 30}ÔºåValidation RMSE: 2.9131449247468506\n",
      "Params: {'regParam': 1.0, 'maxIter': 50}ÔºåValidation RMSE: 2.9131449247468195\n",
      "Linear Regression Best Params: {'regParam': 0.01, 'maxIter': 50}, Linear Regression Best Validation RMSE: 2.7936499275035835\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='overall')\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \n",
    "               .addGrid(lr.maxIter, [10, 30, 50])\n",
    "               .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "lr_best_rmse = float(\"inf\")\n",
    "lr_best_model = None\n",
    "lr_best_params = None\n",
    "\n",
    "\n",
    "for params in paramGrid:\n",
    "    # set params\n",
    "    param_dict = {param.name: val for param, val in params.items()}\n",
    "    \n",
    "    lr.setParams(**param_dict)\n",
    "    \n",
    "    model = lr.fit(train_df)\n",
    "\n",
    "    val_predictions = model.transform(val_df)\n",
    "    val_rmse = evaluator.evaluate(val_predictions)\n",
    "    print(f\"Params: {param_dict}ÔºåValidation RMSE: {val_rmse}\")\n",
    "\n",
    "    # update best params and model\n",
    "    if val_rmse < lr_best_rmse:\n",
    "        lr_best_rmse = val_rmse\n",
    "        lr_best_model = model\n",
    "        lr_best_params = param_dict\n",
    "\n",
    "print(f\"Linear Regression Best Params: {lr_best_params}, Linear Regression Best Validation RMSE: {lr_best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'maxDepth': 4, 'maxIter': 10}ÔºåValidation RMSE: 2.389552564880566\n",
      "Params: {'maxDepth': 4, 'maxIter': 20}ÔºåValidation RMSE: 2.075372082819166\n",
      "Params: {'maxDepth': 4, 'maxIter': 30}ÔºåValidation RMSE: 1.8598984942204393\n",
      "Params: {'maxDepth': 5, 'maxIter': 10}ÔºåValidation RMSE: 2.0075485757555813\n",
      "Params: {'maxDepth': 5, 'maxIter': 20}ÔºåValidation RMSE: 1.7089747401330297\n",
      "Params: {'maxDepth': 5, 'maxIter': 30}ÔºåValidation RMSE: 1.5707517706392125\n",
      "Params: {'maxDepth': 6, 'maxIter': 10}ÔºåValidation RMSE: 1.7870962238669803\n",
      "Params: {'maxDepth': 6, 'maxIter': 20}ÔºåValidation RMSE: 1.5715816121622939\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol='overall')\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "               .addGrid(gbt.maxDepth, [4, 5, 6])\n",
    "               .addGrid(gbt.maxIter, [10, 20, 30])\n",
    "               .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "gbt_best_rmse = float(\"inf\")\n",
    "gbt_best_model = None\n",
    "gbt_best_params = None\n",
    "\n",
    "for params in paramGrid:\n",
    "    # set params\n",
    "    param_dict = {param.name: val for param, val in params.items()}\n",
    "    \n",
    "    gbt.setParams(**param_dict)\n",
    "    \n",
    "    model = gbt.fit(train_df)\n",
    "\n",
    "    val_predictions = model.transform(val_df)\n",
    "    val_rmse = evaluator.evaluate(val_predictions)\n",
    "    print(f\"Params: {param_dict}ÔºåValidation RMSE: {val_rmse}\")\n",
    "\n",
    "    # update best params and model\n",
    "    if val_rmse < gbt_best_rmse:\n",
    "        gbt_best_rmse = val_rmse\n",
    "        gbt_best_model = model\n",
    "        gbt_best_params = param_dict\n",
    "\n",
    "print(f\"GBT Regression Best Params: {gbt_best_params}, GBT Regression Best Validation RMSE: {gbt_best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = gbt_best_model.transform(test_df)\n",
    "\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
